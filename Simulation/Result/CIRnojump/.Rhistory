IV_path<-paste0(Base_wd,'fVP\\Simulation\\Data\\CIR\\IV')
Data_path<-paste0(Base_wd,'fVP\\Simulation\\Data\\CIR\\Price')
Pre_code_path<-paste0(Base_wd,'fVP\\Simulation\\Code\\','PreRequisiteCode')
Base_wd<-'D:\\Academic\\Projects\\'  # Can be configured according to the download path
# Packages Setting
library(gmm)
library(dplyr)
library(KernSmooth)
library(forecast)
## Setting
IV_path<-paste0(Base_wd,'fVP\\Simulation\\Data\\CIR\\IV')
Data_path<-paste0(Base_wd,'fVP\\Simulation\\Data\\CIR\\Price')
Pre_code_path<-paste0(Base_wd,'fVP\\Simulation\\Code\\','PreRequisiteCode')
Result_path<-paste0(Base_wd,'fVP\\Simulation\\','Result\\CIRnojump')
setwd(Pre_code_path)
source('Likelihood_function.R',encoding = 'UTF-8')
## Determine the stock code and index code for forecasting.
Stock_vector<-list.files(Data_path)
sorted_indices <- order(sapply(Stock_vector,function(x) as.numeric(substr(x, 25, nchar(x)-4))))
Stock_vector<-Stock_vector[sorted_indices]
IV_vector<-list.files(IV_path)
sorted_indices <- order(sapply(IV_vector,function(x) as.numeric(substr(x, 12, nchar(x)-4))))
IV_vector<-IV_vector[sorted_indices]
## Predicting based on the baseline model
for(index in 1:1){
stock_code<-Stock_vector[index]
IV_code<-IV_vector[index]
# Importing data and pre-computations
setwd(Data_path)
opening_price <- read.table(stock_code, header = F)
opening_price <- matrix(opening_price[seq(1,nrow(opening_price),by=48),1],nrow=1)[1,1:1500]
normal_data <- read.table(stock_code, header = T)|>
as.matrix()|>
matrix(nrow = 48, byrow = F)
setwd(IV_path)
IV<-read.table(IV_code,header=F)[,1]
normal_data <- rbind(opening_price,normal_data)
normal_data_range<-apply(normal_data,2,max)-apply(normal_data,2,min)
normal_r2<-apply(normal_data,2,diff)^2
RV<-(apply(normal_r2,2,sum))
# Parameter Setting for Predicting
step_length <- 250
window_width <- 1250
start=(ncol(normal_data)-step_length-window_width+1)
delta<-1/nrow(normal_data)
fore_num<-step_length
Lw=window_width #用于估计模型的时间长度
days_num=Lw+fore_num #用于估计的数据和用于对比的数据总共的窗宽
logreturn_5min<-apply(normal_data,2,diff)
logreturn_daily<-unlist(as.vector((normal_data[49,])-normal_data[1,]))
RV_daily<-tail(RV,days_num)
logreturn_daily_square<-logreturn_daily^2
hlt_square_ori<-tail(normal_data_range^2,days_num)
data_daily<-data.frame(
"daily_Return"=logreturn_daily,
"daily_RV"=RV_daily
)
RV_test<-tail(RV,fore_num)
IV_test<-tail(IV,fore_num)
# Predicting
## GARCH Model
forecast_GARCH=numeric(fore_num)
for (day_id in 1:fore_num){
data_est=as.matrix(data_daily[day_id:(day_id+Lw-1),])
fit_RV=nlminb(inig, llfg, data=data_est, lower=lowerg, upper=upperg)
theta=fit_RV[["par"]]
forecast_GARCH[day_id]=iterg(theta,data_est)
print(c(index,'GARCH',day_id))
}
## RGARCH Model
forecast_RGARCH=numeric(fore_num)
for (day_id in 1:fore_num){
data_est=as.matrix(data_daily[day_id:(day_id+Lw-1),])
fit_RV=nlminb(ini0, llf0, data=data_est, lower=lower0, upper=upper0)
theta=fit_RV[["par"]]
forecast_RGARCH[day_id]=iter0(theta,data_est)
print(c(index,'RGARCH',day_id))
}
## MEM Model
forecast_MEM=numeric(fore_num)
for (day_id in 1:fore_num){
data=logreturn_daily[(day_id):(day_id-1+Lw)]
data_square=logreturn_daily_square[day_id:(day_id-1+Lw)]
data_RV=RV_daily[day_id:(day_id+Lw-1)]
hlt_square=hlt_square_ori[day_id:(day_id-1+Lw)]
fit_RV=nlminb(ini_MEM,llf_MEM,data=data,data_square=data_square,
lower=lower_MEM, upper=upper_MEM,
data_RV=data_RV,hlt_square=hlt_square)
theta_result=fit_RV[["par"]]
forecast_MEM[day_id]=iter_MEM(theta_result,data_square=data_square,
data=data,hlt_square = hlt_square,
data_RV=data_RV)#
print(c(index,'MEM',day_id))
}
## HAR Model
forecast_HAR=numeric(fore_num)
for (day_id in 1:fore_num){
data<-data_daily
data_HAR=matrix(0,Lw,4)
for (k in 22:Lw){
data_HAR[k,1]=data[(k+day_id-1),2]
data_HAR[k,2]=data[(k+day_id-2),2]
data_HAR[k,3]=mean(data[(k+day_id-6):(k+day_id-3),2])
data_HAR[k,4]=mean(data[(k+day_id-23):(k+day_id-7),2])
}
coef=lm(data_HAR[,1]~data_HAR[,2:4])[["coefficients"]]
forecast_HAR[day_id]=coef[1]+coef[2]*data_HAR[Lw,2]+coef[3]*data_HAR[Lw,3]+coef[4]*data_HAR[Lw,4]
print(c(index,'HAR',day_id))
}
## HEAVY Model
forecast_heavy=numeric(fore_num)
for (day_id in 1:fore_num){
data_est=logreturn_daily[day_id:(day_id-1+Lw)]
data_RV=RV_daily[day_id:(day_id+Lw-1)]
fit_RV=nlminb(ini_heavy, llf_heavy, data=data_est,
lower=lower_heavy, upper=upper_heavy,data_RV=data_RV)
theta_result=fit_RV[["par"]]
forecast_heavy[day_id]=iter_heavy(theta_result,data_est,data_RV)#
print(c(index,'HEAVY',day_id))
}
# Result Save
funf_result<-list()
funf_result[['RV_test']]<-IV_test
funf_result[["different methods"]][["GARCH"]]<-forecast_GARCH
funf_result[["different methods"]][["RGARCH"]]<-forecast_RGARCH
funf_result[["different methods"]][["HAR_RV"]]<-forecast_HAR
funf_result[["different methods"]][["HEAVY"]]<-forecast_heavy
funf_result[["different methods"]][["MEM"]]<-forecast_MEM
save(funf_result,file =
paste0(Result_path,'\\',
substr(Stock_vector[index],1,nchar(Stock_vector[index])-4),
"_funf_result"))
}
i=1
paste('fVP',stock_code,i)
Base_wd<-'D:\\Academic\\Projects\\'  # Can be configured according to the download path
type<-'CIRnojump'  # can choose 'Smooth', 'CIRnojump', or 'CIRjump'
Base_wd<-'D:\\Academic\\Projects\\'  # Can be configured according to the download path
type<-'CIRnojump'  # can choose 'Smooth', 'CIRnojump', or 'CIRjump'
## Automatic settings
if(type=='Smooth'){
IV_path<-paste0(Base_wd,'fVP\\Simulation\\Data\\Smooth\\IV')
Data_path<-paste0(Base_wd,'fVP\\Simulation\\Data\\Smooth\\Price')
Pre_code_path<-paste0(Base_wd,'fVP\\Simulation\\Code\\PreRequisiteCode')
Result_path<-paste0(Base_wd,'fVP\\Simulation\\','Result\\Smooth')
}else if(type=='CIRnojump'){
IV_path<-paste0(Base_wd,'fVP\\Simulation\\Data\\CIR\\IV')
Data_path<-paste0(Base_wd,'fVP\\Simulation\\Data\\CIR\\Price')
Pre_code_path<-paste0(Base_wd,'fVP\\Simulation\\Code\\PreRequisiteCode')
Result_path<-paste0(Base_wd,'fVP\\Simulation\\','Result\\CIRnojump')
}else if(type=='CIRjump'){
IV_path<-paste0(Base_wd,'fVP\\Simulation\\Data\\CIR\\IV')
Data_path<-paste0(Base_wd,'fVP\\Simulation\\Data\\CIR\\Jump_price')
Pre_code_path<-paste0(Base_wd,'fVP\\Simulation\\Code\\PreRequisiteCode')
Result_path<-paste0(Base_wd,'fVP\\Simulation\\','Result\\CIRjump')
}
IV_path
Data_path
# fVP
setwd(Pre_code_path)
source('kernel_predict_functions.R',encoding = "UTF-8")
source('sample_functions.R',encoding = "UTF-8")
## fVP
stock_vector<-list.files(paste(Data_path))
sorted_indices <- order(sapply(stock_vector,function(x) as.numeric(substr(x, 25, nchar(x)-4))))
stock_vector<-stock_vector[sorted_indices]
fpc_number_vector<-matrix(NA,ncol=3,nrow=length(stock_vector))
fpc_number_vector[,1]<-1:length(stock_vector)
colnames(fpc_number_vector)<-c('index','fpc_number','variance_explained')
index=1
stock_code<-stock_vector[index]
setwd(Data_path)
# Importing data and pre-computations
opening_price <- read.table(stock_code, header = F)
opening_price <- matrix(opening_price[seq(1,nrow(opening_price),by=48),1],nrow=1)[1,1:1500]
normal_data <- read.table(stock_code, header = T)|>
as.matrix()|>
matrix(nrow = 48, byrow = F)
normal_data <- rbind(opening_price,normal_data)
Z<-(normal_data)|>apply(2,diff)
delta<-1/nrow(Z)
Z<-1/sqrt(delta)*Z
# Parameter Setting for Predicting
step_length <- 250
window_width <- 1250
start=(ncol(normal_data)-step_length-window_width+1)
# Cross-validate Using the First Window
ob_time<-seq(delta:1,by=delta)
Z1<-Z[,start:(start+window_width-1)];
Z1[0>Z1&Z1>=-5*10^(-15)]<-max(Z1[Z1<=-5*10^(-15)])
Z1[0<=Z1&Z1<=5*10^(-15)]<-min(Z1[Z1>=5*10^(-15)])
data_cvtest<-log((Z1^2))-q0
data_cvtest_mean<-apply(data_cvtest,1,mean)
cv_list<-list()
for (date in 1:ncol(data_cvtest)){
Gdate_cvtest<-(data_cvtest[,date]-data_cvtest_mean)%*%
(t(data_cvtest[,date]-data_cvtest_mean))
cv_list[[date]]<-Gdate_cvtest
}
# Determine the Number of Principal Components
cumulative_variance_explained<-normal_fpc_score(data_cvtest,
window_width)$variance_explained
fpc_number<-max(which(cumulative_variance_explained>=
0.95)[1])
fpc_number_vector[,2][index]=fpc_number
fpc_number_vector[,3][index]<-cumulative_variance_explained[fpc_number]
# Rolling forecast
V_result_fpckr<-numeric(step_length)
V_result_fpcVAR<-numeric(step_length)
i=1
print(paste('fVP',stock_code,i))
#functional principle components scores
DATA<-Z[,i:(i+window_width-1)];
DATA[0>DATA&DATA>=-5*10^(-15)]<-max(DATA[DATA<=-5*10^(-15)])
DATA[0<=DATA&DATA<=5*10^(-15)]<-min(DATA[DATA>=5*10^(-15)])
if(type=='CIRjump'){
# determine the threshold
BV<-(pi/2)*apply(abs(DATA[-nrow(DATA),]*DATA[-1,]),2,sum)
RV<-apply(DATA,2,sum)
threshold<-3*sqrt(pmin(BV,RV))*delta^(3/8)
# truncation
for(col in 1:ncol(Z1)){
DATA[,col][abs(DATA[,col])>threshold[col]]<-threshold[col]
}
}else{
NULL
}
DATA<-log(DATA^2)-q0
fpc<-normal_fpc_score(DATA,window_width)
fpc_score<-function(i,k){
delta*sum(((DATA[,i]-fpc[["1d_mean"]])*fpc[["positive_elements"]]$fpc_fun[,k]))#计算得到FPC分数
}
fpc_score<-Vectorize(fpc_score)
day<-c(1:ncol(DATA));fpc_fun_number<-c(1:fpc_number);
predictor_fpc_scores<-outer(day,fpc_fun_number,"fpc_score")
data_learning<-t(predictor_fpc_scores)
#fpcVAR approach
predict_fpcVAR_scores<-data.frame(t(data_learning))%>%
VAR_FPC_SCORES(Knumber=fpc_number)
V_result_fpcVAR[i]<-
sum(delta*exp(fpc$'1d_mean'+
predict_fpcVAR_scores%*%
t(as.matrix(fpc$
positive_elements$
fpc_fun[,1:fpc_number],
nrow=fpc_number))))
# fpckr approach
if(i%%90==1){
hv<-kernel_predictor_CV(data_learning,10,initial_hv=0)$par
}else{
hv=hv
}
predict_fpckr_scores<-kernel_estimator(data_learning,hv)[1:fpc_number]
V_result_fpckr[i]<-
sum(delta*exp(fpc$'1d_mean'+
predict_fpckr_scores%*%
t(as.matrix(fpc$
positive_elements$
fpc_fun[,1:fpc_number],
nrow=fpc_number))))
for(i in 1:step_length){
print(paste('fVP',stock_code,i))
#functional principle components scores
DATA<-Z[,i:(i+window_width-1)];
DATA[0>DATA&DATA>=-5*10^(-15)]<-max(DATA[DATA<=-5*10^(-15)])
DATA[0<=DATA&DATA<=5*10^(-15)]<-min(DATA[DATA>=5*10^(-15)])
if(type=='CIRjump'){
# determine the threshold
BV<-(pi/2)*apply(abs(DATA[-nrow(DATA),]*DATA[-1,]),2,sum)
RV<-apply(DATA,2,sum)
threshold<-3*sqrt(pmin(BV,RV))*delta^(3/8)
# truncation
for(col in 1:ncol(Z1)){
DATA[,col][abs(DATA[,col])>threshold[col]]<-threshold[col]
}
}else{
NULL
}
DATA<-log(DATA^2)-q0
fpc<-normal_fpc_score(DATA,window_width)
fpc_score<-function(i,k){
delta*sum(((DATA[,i]-fpc[["1d_mean"]])*fpc[["positive_elements"]]$fpc_fun[,k]))#计算得到FPC分数
}
fpc_score<-Vectorize(fpc_score)
day<-c(1:ncol(DATA));fpc_fun_number<-c(1:fpc_number);
predictor_fpc_scores<-outer(day,fpc_fun_number,"fpc_score")
data_learning<-t(predictor_fpc_scores)
#fpcVAR approach
predict_fpcVAR_scores<-data.frame(t(data_learning))%>%
VAR_FPC_SCORES(Knumber=fpc_number)
V_result_fpcVAR[i]<-
sum(delta*exp(fpc$'1d_mean'+
predict_fpcVAR_scores%*%
t(as.matrix(fpc$
positive_elements$
fpc_fun[,1:fpc_number],
nrow=fpc_number))))
# fpckr approach
if(i%%90==1){
hv<-kernel_predictor_CV(data_learning,10,initial_hv=0)$par
}else{
hv=hv
}
predict_fpckr_scores<-kernel_estimator(data_learning,hv)[1:fpc_number]
V_result_fpckr[i]<-
sum(delta*exp(fpc$'1d_mean'+
predict_fpckr_scores%*%
t(as.matrix(fpc$
positive_elements$
fpc_fun[,1:fpc_number],
nrow=fpc_number))))
}
V_result_fpckr
result_name<-substr(stock_code_vector[index],
1, nchar(stock_code_vector[index]) - 4)
result_name<-substr(stock_vector[index],
1, nchar(stock_vector[index]) - 4)
result_name
name0<-paste0(result_name,"_funf_result")
load(paste(Result_path,name0,sep="\\"))
View(funf_result)
funf_result[["different methods"]][["fpckr"]]<-V_result_fpckr
funf_result[["different methods"]][["fpcVAR"]]<-V_result_fpcVAR
View(funf_result)
paste0(Result_path,'\\',
name0)
# Setting
Base_wd<-'D:\\Academic\\Projects\\'  # Can be configured according to the download path
type<-'CIRnojump'  # can choose 'Smooth', 'CIRnojump', or 'CIRjump'
## Automatic settings
Pre_code_path<-paste0(Base_wd,'fVP\\Simulation\\Code\\PreRequisiteCode')
source('AutoSetting.R')
source('AutoSetting.R',encoding = "UTF-8")
## Automatic settings
Pre_code_path<-paste0(Base_wd,'fVP\\Simulation\\Code\\PreRequisiteCode')
setwd(Pre_code_path)
source('AutoSetting.R',encoding = "UTF-8")
## BaselineModel
source('BaselineModel',encoding='UTF-8')
setwd(Pre_code_path)
## BaselineModel
source('BaselineModel',encoding='UTF-8')
setwd(Pre_code_path)
source('AutoSetting.R',encoding = "UTF-8")
## BaselineModel
source('BaselineModel.R',encoding='UTF-8')
## fVP
source('fVP.R',encoding='UTF-8')
## fVP
setwd(Pre_code_path)
source('fVP.R',encoding='UTF-8')
# Result Analysis
Result_vector<-list.files(Result_path)
Result_vector
load(Result_vector[1])
getwd()
# Result Analysis
setwd(Result_path)
Result_vector<-list.files()
load(Result_vector[1])
View(funf_result)
method_name<-names(funf_result$`different methods`)
method_name
loss_fun<-matrix(NA,ncol=length(method_name),nrow=length(Result_vector))
View(loss_fun)
colnames(loss_fun)<-method_name
loss_fun<-c('MAE','RMSE','HMAE','HRMSE','AMAPE')
lossfun_Result<-array(NA,dim=c(length(loss_fun),length(method_name),length(Result_vector)))
View(funf_result)
method_index=1
method=method_name[method_index]
mean(abs(funf_result$RV_test-funf_result$`different methods`$method))
funf_result$RV_test
funf_result$`different methods`$method
funf_result$`different methods`[method]
funf_result$`different methods`
funf_result$`different methods`[method]
funf_result$`different methods`[[method]]
mean(abs(funf_result$RV_test-funf_result$`different methods`[[method]]))
for(method_index in 1:length(method_name)){
method=method_name[method_index]
lossfun_Result[1,method_index,index]<-mean(abs(funf_result$RV_test-funf_result$`different methods`[[method]]))
}
lossfun_Result
lossfun_Result[,,1]
dimnames(lossfun_Result)<-list(loss_fun,method_name,Result_vector)
lossfun_Result
# MAE
for(method_index in 1:length(method_name)){
method=method_name[method_index]
lossfun_Result[1,method_index,index]<-mean(abs(funf_result$RV_test-funf_result$`different methods`[[method]]))
}
lossfun_Result
# RMSE
for(method_index in 1:length(method_name)){
method=method_name[method_index]
lossfun_Result[2,method_index,index]<-sqrt(mean((funf_result$RV_test-funf_result$'different methods'[[method]])^2))
}
lossfun_Result
# Result Analysis
setwd(Result_path)
Result_vector<-list.files()
load(Result_vector[1])
method_name<-names(funf_result$`different methods`)
loss_fun<-c('MAE','RMSE','HMAE','HRMSE','AMAPE')
lossfun_Result<-array(NA,dim=c(length(loss_fun),length(method_name),length(Result_vector)))# lossfun,method, trajectories
dimnames(lossfun_Result)<-list(loss_fun,method_name,Result_vector)
for(index in 1:length(Result_vector)){
name<-Result_vector[index]
load(paste(Result_path,name,sep='\\'))
funf_result_new<-funf_result
# MAE
for(method_index in 1:length(method_name)){
method=method_name[method_index]
lossfun_Result[1,method_index,index]<-10000*mean(abs(funf_result$RV_test-funf_result$`different methods`[[method]]))
}
# RMSE
for(method_index in 1:length(method_name)){
method=method_name[method_index]
lossfun_Result[2,method_index,index]<-10000*sqrt(mean((funf_result$RV_test-funf_result$'different methods'[[method]])^2))
}
# HMAE
for(method_index in 1:length(method_name)){
method=method_name[method_index]
lossfun_Result[3,method_index,index]<-mean(abs((funf_result$'different methods'[[method]])/(funf_result$RV_test)-1))
}
# HRMSE
for(method_index in 1:length(method_name)){
method=method_name[method_index]
lossfun_Result[4,method_index,index]<-sqrt(mean(((funf_result$'different methods'[[method]])/(funf_result$RV_test)-1)^2))
}
# AMAPE
for(method_index in 1:length(method_name)){
method=method_name[method_index]
lossfun_Result[5,method_index,index]<-mean(abs((funf_result$RV_test-funf_result$`different methods`[[method]])/
(funf_result$RV_test+funf_result$`different methods`[[method]])))
}
}
lossfun_Result[,,1]
lossfun_Result[,,2]
lossfun_Result[1,,]
a<-lossfun_Result[1,,]
View(a)
# Result Analysis
setwd(Pre_code_path)
source('ResultAnalysis.R',encoding='UTF-8')
lossfun_Result
##  Array 'lossfun_Result': Each dimension represents the loss function, prediction method, and sample trajectory respectively;
##  Any dimension can be chosen for observation, for example, observing the MAE loss function.
MAEmat<-lossfun_Result[1,,]
MAEmat
# Working Directory
Base_wd<-'D:\\Academic\\Projects\\'  # Can be configured according to the download path
type<-'CIRnojump'  # can choose 'Smooth', 'CIRnojump', or 'CIRjump'
# Automatic settings
Pre_code_path<-paste0(Base_wd,'fVP\\Simulation\\Code\\PreRequisiteCode')
setwd(Pre_code_path)
source('AutoSetting.R',encoding = "UTF-8")
## Baseline Model
source('BaselineModel.R',encoding='UTF-8')
## fVP
setwd(Pre_code_path)
source('fVP.R',encoding='UTF-8')
## fVP
setwd(Pre_code_path)
source('fVP.R',encoding='UTF-8')
## fVP
setwd(Pre_code_path)
source('fVP.R',encoding='UTF-8')
# Result Analysis
setwd(Pre_code_path)
source('ResultAnalysis.R',encoding='UTF-8') # Get Array 'lossfun_Result'
##  Array 'lossfun_Result': Each dimension represents the loss function, prediction method, and sample trajectory respectively;
##  Any dimension can be chosen for observation, for example, observing the MAE loss function.
MAEmat<-lossfun_Result[1,,]
MAEmat
## Plot
density_est<-apply(MAEmat,1,density)
View(density_est)
plot(density_est$GARCH)
MAEmat
View(MAEmat)
points(density_est$HEAVY)
points(density_est$fpcVAR,col='red')
#parameter for plot
library(RColorBrewer)
max_x<-c();max_y<-c();min_x<-c()
for(i in 1:length(density_est)){
density_test<-density_est[[i]]
max_x <- c(max_x,max(density_test$x));min_x<-c(min_x,min(density_test$x))
max_y <- c(max_y,max(density_test$y))
}
max_x<-max(max_x);max_y<-max(max_y);min_x<-min(min_x)
color_density<-brewer.pal(round(length(density_est)),'Set1')
plot(density_est[[1]],main='',
col=color_density[1],
xlim=c(min_x, max_x), ylim=c(0, max_y), xlab=lossfunction, ylab="Density")
plot(density_est[[1]],main='',
col=color_density[1],
xlim=c(min_x, max_x), ylim=c(0, max_y), xlab='MAE', ylab="Density")
lwd<-c()
for(i in 2:length(density_est)){
if(names(density_est)[i]=='fpcVAR'){
lines(density_est[[i]],col=color_density[i],lwd=3)
lwd<-c(lwd,3)
}else{
lines(density_est[[i]],col=color_density[i])
lwd<-c(lwd,1)
}
}
legend("topright", legend=names(density_est), col=color_density, lwd = c(1,lwd),lty=1)
??MSwM
